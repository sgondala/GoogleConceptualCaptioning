python train.py --caption_model att2in2 --input_json data/cocotalk_with_cc_vocab_rm_8_same_order.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_label data/cocotalk_with_cc_vocab.h5 --batch_size 50 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/coco_on_base_rm_8_exp_1_3e5/ --save_checkpoint_every 160 --val_images_use 5000 --max_epochs 3 --rnn_size 2400 | tee model_train_outputs/coco_on_base_rm_8_exp_1_3e5.txt

python train.py --caption_model att2in2 --input_json data/nocapstalk_with_cc_vocab.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_label data/nocapstalk_with_cc_vocab.h5 --batch_size 10 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/nocaps_train_no_checkpoint_jan_24_3e5 --save_checkpoint_every 6000 --val_images_use 150 --max_epochs 10 --rnn_size 2400


Eval on coco - 


python eval.py --model checkpoints/coco_on_cc_rm_8_exp_2_15e5/model-12000.pth --infos_path checkpoints/coco_on_cc_rm_8_exp_2_15e5/infos_-12000.pkl  --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --num_images -1 --input_json data/cocotalk_with_cc_vocab_rm_8_same_order.json --split train --out_file eval_results/coco_on_cc_rm_8_15e5_12k --batch_size 1000

checkpoints/coco_sc_on_exp2_1e5_vilbert_10/model-400.pth

Nocaps finetune - 

python train.py --caption_model att2in2 --input_json data/nocapstalk_with_cc_vocab.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_label data/nocapstalk_with_cc_vocab.h5 --batch_size 50 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/nocaps_finetune_coco_base_3e5/ --save_checkpoint_every 20 --val_images_use 200 --max_epochs 30 --start_from checkpoints/coco_base_jan_25_3e5/ --rnn_size 2400

python train.py --caption_model att2in2 --input_json data/cocotalk_with_cc_vocab.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_label data/cocotalk_with_cc_vocab.h5 --batch_size 10 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path conceptual_captions_plus_coco_finetune_dec13_3e5_3 --save_checkpoint_every 6000 --val_images_use 5000 --max_epochs 3 --start_from conceptual_base_on_att2in/ --rnn_size 2400


Train self critical coco 

python train.py --caption_model att2in2 --input_json data/cocotalk_with_cc_vocab_rm_8_same_order_for_self_critical.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/trainval_resnet101_faster_rcnn_genome_36.tsv --input_label data/cocotalk_with_cc_vocab.h5 --batch_size 50 --learning_rate 5e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/coco_sc_on_exp2_5e5_vilbert_10 --save_checkpoint_every 100 --val_images_use 5000 --max_epochs 5 --rnn_size 2400 --self_critical_after 0 --config_file config/bert_base_6layer_6conect.json --cider_model ../vilbert_beta/checkpoints/coco_minus_8_no_random/pytorch_model_10.bin --seq_per_img 1 --start_from checkpoints/coco_on_cc_rm_8_exp_2_15e5/

Train on nocaps self critical 

python train.py --caption_model att2in2 --input_json data/nocapstalk_with_cc_vocab.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/nocaps_val_vg_detector_features_adaptive.h5 --input_label data/nocapstalk_with_cc_vocab.h5 --batch_size 10 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/temp --save_checkpoint_every 20 --val_images_use 200 --max_epochs 30 --rnn_size 2400 --self_critical_after 0 --config_file config/bert_base_6layer_6conect.json --cider_model ../vilbert_beta/checkpoints/clean_coco_and_nocaps_multi_train_ratio_3/pytorch_model_19.bin --seq_per_img 1 --start_from checkpoints/conceptual_base_on_att2in/

All nocaps images sc train 

python train.py --caption_model att2in2 --input_json data/nocapstalk_with_cc_vocab_only_one_val.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/nocaps_val_vg_detector_features_adaptive.h5 --input_label data/nocapstalk_with_cc_vocab_fake_for_sc.h5 --batch_size 10 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/nocaps_sc_after_0_on_cc_all_images/ --save_checkpoint_every 20 --val_images_use 200 --max_epochs 10 --rnn_size 2400 --self_critical_after 0 --config_file config/bert_base_6layer_6conect.json --cider_model ../vilbert_beta/checkpoints/clean_coco_and_nocaps_multi_train_ratio_3/pytorch_model_19.bin --seq_per_img 1 --start_from checkpoints/conceptual_base_on_att2in/


Train on nocaps self critical with ref caps

python train.py --caption_model att2in2 --input_json data/nocapstalk_with_cc_vocab.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/nocaps_val_vg_detector_features_adaptive.h5 --input_label data/nocapstalk_with_cc_vocab.h5 --batch_size 10 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/temp --save_checkpoint_every 20 --val_images_use 200 --max_epochs 30 --rnn_size 2400 --self_critical_after 0 --cached_tokens coco-train-idxs --use_model_for_sc_train 0 --seq_per_img 1

Train on coco self critical with ref caps

python train.py --caption_model att2in2 --input_json data/cocotalk_with_cc_vocab.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/trainval_resnet101_faster_rcnn_genome_36.tsv --input_label data/cocotalk_with_cc_vocab.h5 --batch_size 10 --learning_rate 3e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/coco_train_on_cc_using_self_critical_after_0_ref_caps/ --save_checkpoint_every 6000 --val_images_use 5000 --max_epochs 5 --rnn_size 2400 --self_critical_after 0  --seq_per_img 1 --start_from checkpoints/conceptual_base_on_att2in/ --cached_tokens coco-train-idxs --use_model_for_sc_train 0



python eval.py --model log_fc_iter1_coco_finetune/model-732000.pth --infos_path log_fc_iter1_coco_finetune/infos_td-best-732000.pkl --image_folder /srv/datasets/coco/images/val2014/ --num_images 5 


python eval.py --model log_fc_iter1_coco_finetune/model-732000.pth --infos_path log_fc_iter1_coco_finetune/infos_td-best-732000.pkl --image_folder /srv/datasets/coco/images/val2014/ --num_images 5 --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_box_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv

python eval.py --model checkpoints_coco_train_raw_topdown/model.pth --infos_path checkpoints_coco_train_raw_topdown/infos_.pkl --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_box_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --num_images 5 --input_json data/nocapstalk.json --split train


python eval.py --model checkpoints_coco_train_raw_topdown/model.pth --infos_path checkpoints_coco_train_raw_topdown/infos_.pkl --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --num_images 5 --input_json data/nocapstalk.json --split train


Saved model checkpoints - 

Namespace(att_feat_size=2048, att_hid_size=512, batch_size=250, beam_size=1, bleu_reward_weight=0, block_trigrams=0, cached_tokens='google-train-idxs', caption_model='att2in2', checkpoint_path='log_best_smoothing', cider_reward_weight=1, current_lr=0.00013107200000000006, drop_prob_lm=0.5, drop_worst_after=-1, drop_worst_rate=0, entropy_reward_weight=0, fc_feat_size=2048, grad_clip=0.1, id='best_smoothing', initialize_retrieval=None, input_att_dir='/scratch/rluo/googlebu_att.lmdb', input_box_dir='data/cocotalk_box', input_encoding_size=512, input_fc_dir='data/googlebu_fc', input_json='data/googletalk.json', input_label_h5='data/googletalk_label.h5', label_smoothing=0.1, language_eval=1, learning_rate=0.0005, learning_rate_decay_every=3, learning_rate_decay_rate=0.8, learning_rate_decay_start=0, length_penalty='', load_best_score=1, logit_layers=1, losses_log_every=25, max_epochs=35, max_length=20, noamopt=False, noamopt_factor=1, noamopt_warmup=2000, norm_att_feat=0, norm_box_feat=0, num_layers=1, optim='adam', optim_alpha=0.9, optim_beta=0.999, optim_epsilon=1e-08, reduce_on_plateau=False, remove_bad_endings=0, retrieval_reward_weight=0, rnn_size=2400, rnn_type='lstm', save_checkpoint_every=6000, save_history_ckpt=1, scheduled_sampling_increase_every=5, scheduled_sampling_increase_prob=0.05, scheduled_sampling_max_prob=0.25, scheduled_sampling_start=-1, self_critical_after=-1, seq_length=19, seq_per_img=1, start_from='log_best_smoothing', struc_use_logsoftmax=False, structure_after=-1, structure_loss_type='seqnll', structure_loss_weight=1, structure_sample_n=16, train_only=0, use_att=True, use_bn=0, use_box=0, use_fc=False, val_images_use=10000, vocab_size=16303, vse_embed_size=1024, vse_loss_type='contrastive', vse_margin=0.2, vse_max_violation=1, vse_measure='cosine', vse_model='None', vse_no_imgnorm=0, vse_num_layers=1, vse_pool_type='last', vse_rnn_type='gru', vse_use_abs=0, vse_word_dim=300, weight_decay=0)

model sizes 

['embed.0.weight', 'att_embed.0.weight', 'att_embed.0.bias', 'logit.weight', 'logit.bias', 'ctx2att.weight', 'ctx2att.bias', 'core.a2c.weight', 'core.a2c.bias', 'core.i2h.weight', 'core.i2h.bias', 'core.h2h.weight', 'core.h2h.bias', 'core.attention.h2att.weight', 'core.attention.h2att.bias', 'core.attention.alpha_net.weight', 'core.attention.alpha_net.bias']

[(16304, 512), (2400, 2048), (2400,), (16304, 2400), (16304,), (512, 2400), (512,), (4800, 2400), (4800,), (12000, 512), (12000,), (12000, 2400), (12000,), (512, 2400), (512,), (1, 512), (1,)]



Mine Att2in2

Opt input Namespace(att_feat_size=2048, att_hid_size=512, batch_size=10, beam_size=1, bleu_reward_weight=0, block_trigrams=0, cached_tokens='google-train-idxs', caption_model='att2in2', checkpoint_path='conceptual_captions_plus_coco_finetune_dec13_3e5_3', cider_reward_weight=1, drop_prob_lm=0.5, drop_worst_after=-1, drop_worst_rate=0, entropy_reward_weight=0, fc_feat_size=2048, grad_clip=0.1, id='', initialize_retrieval=None, input_att_dir='/srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv', input_box_dir='data/cocotalk_box', input_encoding_size=512, input_fc_dir='/srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv', input_json='data/cocotalk_with_cc_vocab.json', input_label_h5='data/cocotalk_with_cc_vocab.h5', label_smoothing=0, language_eval=0, learning_rate=3e-05, learning_rate_decay_every=3, learning_rate_decay_rate=0.8, learning_rate_decay_start=0, length_penalty='', load_best_score=1, logit_layers=1, losses_log_every=25, max_epochs=5, max_length=20, noamopt=False, noamopt_factor=1, noamopt_warmup=2000, norm_att_feat=0, norm_box_feat=0, num_layers=1, optim='adam', optim_alpha=0.9, optim_beta=0.999, optim_epsilon=1e-08, reduce_on_plateau=False, remove_bad_endings=0, retrieval_reward_weight=0, rnn_size=2400, rnn_type='lstm', save_checkpoint_every=6000, save_history_ckpt=1, scheduled_sampling_increase_every=5, scheduled_sampling_increase_prob=0.05, scheduled_sampling_max_prob=0.25, scheduled_sampling_start=0, self_critical_after=-1, seq_per_img=5, start_from='conceptual_base_on_att2in/', struc_use_logsoftmax=False, structure_after=-1, structure_loss_type='seqnll', structure_loss_weight=1, structure_sample_n=16, train_only=0, use_bn=0, use_box=0, val_images_use=5000, vse_embed_size=1024, vse_loss_type='contrastive', vse_margin=0.2, vse_max_violation=1, vse_measure='cosine', vse_model='None', vse_no_imgnorm=0, vse_num_layers=1, vse_pool_type='last', vse_rnn_type='gru', vse_use_abs=0, vse_word_dim=300, weight_decay=0)

python eval.py --model checkpoints/nocaps_finetune_coco_base_3e4/model.pth --infos_path checkpoints/nocaps_finetune_coco_base_3e4/infos_.pkl --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_att_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --input_box_dir /srv/share2/sgondala/tmp/trainval_36/nocaps_val_vg_detector_features_adaptive.h5 --num_images 5 --input_json data/nocapstalk_with_cc_vocab_old.json --split train --out_file_path eval_results/cocobase_plus_nocaps_finetune


Coco eval 

python eval.py --model checkpoints/coco_train_on_cc_using_self_critical_after_3/model-30000.pth --infos_path checkpoints/coco_train_on_cc_using_self_critical_after_3/infos_-30000.pkl --num_images -1 --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_box_dir /srv/share2/sgondala/tmp/trainval_36/trainval_resnet101_faster_rcnn_genome_36.tsv --input_json data/cocotalk_with_cc_vocab.json --split val --out_file_path eval_results/coco_val_captions_on_coco_train_on_cc_sc_after_3_30k

Shapes:

Conceptual base - [(16304, 512), (2400, 2048), (2400,), (16304, 2400), (16304,), (512, 2400), (512,), (4800, 2400), (4800,), (12000, 512), (12000,), (12000, 2400), (12000,), (512, 2400), (512,), (1, 512), (1,)]
Coco finetune   - [(16304, 512), (2400, 2048), (2400,), (16304, 2400), (16304,), (512, 2400), (512,), (4800, 2400), (4800,), (12000, 512), (12000,), (12000, 2400), (12000,), (512, 2400), (512,), (1, 512), (1,)]


(WRONG!! ) Coco base -       [(16304, 512), (512, 2048), (512,), (16304, 512), (16304,), (512, 512), (512,), (1024, 512), (1024,), (2560, 512), (2560,), (2560, 512), (2560,), (512, 512), (512,), (1, 512), (1,)]


Models needed 

1. Conceptual base (Done) - conceptual_base_on_att2in - (33, 33, 33, 33)
2. Conceptual base + coco fine tune (Done) - conceptual_captions_plus_coco_finetune_dec13_3e5_5 - (77,62,41,60)
3. Conceptual base + coco fine tune + nocaps fine tune - 
4. Coco base - coco_base_jan_25_3e5 - (74, 57, 29, 53)
5. Coco base + nocaps fine tune - nocaps_finetune_coco_base_3e4 - Before removing duplicates - (106, 81, 72, 83), After - (79, 67, 44, 64)

// Not called for
6. Nocaps base - 

TODO: 

1. Make nocaps files for some file - ref and out
Ref - nocaps_ref_file_ascii.json
Out - nocaps_conceptual_base_with_coco_finetune_1000_images_only_ascii.json
2. Get cider scores for nocaps
Cider - nocaps_cider_scores.json
3. Test on nocaps


Train self critical coco - cider and slor

python train.py --caption_model att2in2 --input_json data/cocotalk_with_cc_vocab_rm_8_same_order_for_self_critical.json --input_fc_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/trainval_resnet101_faster_rcnn_genome_36.tsv --input_att_dir /srv/share2/sgondala/tmp/trainval_36/python3_stuff/trainval_resnet101_faster_rcnn_genome_36.tsv --input_label data/cocotalk_with_cc_vocab.h5 --batch_size 50 --learning_rate 5e-5 --learning_rate_decay_start 0 --scheduled_sampling_start 0 --checkpoint_path checkpoints/coco_sc_on_exp2_5e5_vilbert_10 --save_checkpoint_every 100 --val_images_use 5000 --max_epochs 5 --rnn_size 2400 --self_critical_after 0  --seq_per_img 1 --start_from checkpoints/coco_on_cc_rm_8_exp_2_15e5/ --use_cider --use_slor